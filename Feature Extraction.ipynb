{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e06cb92-b0ed-4fd3-b130-57b10efbe09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 600 feature rows to features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
    "\n",
    "# Paths\n",
    "base_path   = 'data/train'\n",
    "output_csv  = 'features.csv'\n",
    "\n",
    "categories = {\n",
    "    'with_label/clean': 'clean',\n",
    "    'with_label/dirty': 'dirty',\n",
    "    'no_label': 'unknown'\n",
    "}\n",
    "\n",
    "# LBP params\n",
    "LBP_RADIUS   = 1\n",
    "LBP_N_POINTS = 8 * LBP_RADIUS\n",
    "LBP_METHOD   = 'uniform'\n",
    "LBP_N_BINS   = LBP_N_POINTS + 2\n",
    "\n",
    "# HOG params\n",
    "HOG_PIXELS_PER_CELL  = (8, 8)\n",
    "HOG_CELLS_PER_BLOCK  = (2, 2)\n",
    "HOG_ORIENTATIONS     = 9\n",
    "\n",
    "# GLCM distances / angles\n",
    "GLCM_DISTANCES = [1, 2, 4]\n",
    "GLCM_ANGLES    = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "GLCM_PROPS     = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "features = []\n",
    "\n",
    "def extract_features(img_path, label):\n",
    "    try:\n",
    "        # --- Load & basic ---\n",
    "        img = Image.open(img_path)\n",
    "        w, h = img.size\n",
    "        img_cv = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img_cv, (128, 128))\n",
    "        area = w * h\n",
    "\n",
    "        # --- File stats ---\n",
    "        file_kb = os.path.getsize(img_path) / 1024.0\n",
    "        feat = {\n",
    "            'file': os.path.basename(img_path),\n",
    "            'label': label,\n",
    "            'width': w,\n",
    "            'height': h,\n",
    "            'aspect_ratio': round(w/h, 3),\n",
    "            'file_size_kb': round(file_kb, 2),\n",
    "            'edge_density': None  # fill later\n",
    "        }\n",
    "\n",
    "        # --- Color stats ---\n",
    "        arr128 = np.array(img.resize((128,128)))\n",
    "        for ch,name in enumerate(('r','g','b')):\n",
    "            vals = arr128[:,:,ch].ravel().astype(np.float32)\n",
    "            feat[f'avg_{name}']      = float(vals.mean())\n",
    "            feat[f'var_{name}']      = float(vals.var())\n",
    "            feat[f'skew_{name}']     = float(((vals - vals.mean())**3).mean() / (vals.std()**3 + 1e-6))\n",
    "\n",
    "        # --- HSV histograms (first 20 bins each) ---\n",
    "        hsv = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)\n",
    "        for i,ch in enumerate(('h','s','v')):\n",
    "            hist = cv2.calcHist([hsv],[i],None,[256],[0,256]).flatten()[:20]\n",
    "            for j,v in enumerate(hist):\n",
    "                feat[f'{ch}_hist_{j}'] = int(v)\n",
    "\n",
    "        # --- Grayscale & lum hist ---\n",
    "        gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "        ghist = cv2.calcHist([gray],[0],None,[256],[0,256]).flatten()[:20]\n",
    "        for i,v in enumerate(ghist): feat[f'gray_hist_{i}'] = int(v)\n",
    "\n",
    "        lum = (0.299*arr128[:,:,0] + 0.587*arr128[:,:,1] + 0.114*arr128[:,:,2]).astype(np.uint8)\n",
    "        lhist = cv2.calcHist([lum],[0],None,[256],[0,256]).flatten()[:20]\n",
    "        for i,v in enumerate(lhist): feat[f'lum_hist_{i}'] = int(v)\n",
    "\n",
    "        # --- Contrast & Laplacian var (sharpness) ---\n",
    "        feat['contrast']           = int(gray.max() - gray.min())\n",
    "        lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        feat['laplacian_var']      = float(lap.var())\n",
    "\n",
    "        # --- Edge counts ---\n",
    "        can = cv2.Canny(gray,100,200); can_cnt = int((can>0).sum())\n",
    "        sobx= cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=3)\n",
    "        soby= cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=3)\n",
    "        sobm= np.sqrt(sobx**2 + soby**2).astype(np.uint8)\n",
    "        sob_cnt = int((sobm>50).sum())\n",
    "        feat['canny_count']       = can_cnt\n",
    "        feat['sobel_count']       = sob_cnt\n",
    "        feat['edge_density']      = can_cnt / (area + 1e-6)\n",
    "\n",
    "        # --- Center vs Surround edges ---\n",
    "        cx,cy,half = 64,64,32\n",
    "        mask = np.zeros_like(gray, bool)\n",
    "        mask[cy-half:cy+half,cx-half:cx+half]=True\n",
    "        feat['center_edge']   = int((can[mask]>0).sum())\n",
    "        feat['surround_edge'] = int((can[~mask]>0).sum())\n",
    "\n",
    "        # --- HOG (first 50 dims) ---\n",
    "        hf = hog(gray,\n",
    "                 orientations=HOG_ORIENTATIONS,\n",
    "                 pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "                 cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "                 block_norm='L2-Hys',\n",
    "                 feature_vector=True)[:50]\n",
    "        for i,v in enumerate(hf): feat[f'hog_{i}'] = float(v)\n",
    "\n",
    "        # --- LBP (first 20 bins) ---\n",
    "        lbp = local_binary_pattern(gray, LBP_N_POINTS, LBP_RADIUS, method=LBP_METHOD)\n",
    "        lh, _ = np.histogram(lbp.ravel(), bins=LBP_N_BINS, range=(0,LBP_N_BINS))\n",
    "        lh = lh.astype(float)/ (lh.sum()+1e-6)\n",
    "        for i,v in enumerate(lh[:20]): feat[f'lbp_{i}'] = float(v)\n",
    "\n",
    "        # --- GLCM / Haralick props ---\n",
    "        glcm = graycomatrix(gray, distances=GLCM_DISTANCES, angles=GLCM_ANGLES,\n",
    "                            symmetric=True, normed=True)\n",
    "        for prop in GLCM_PROPS:\n",
    "            val = graycoprops(glcm, prop).mean()\n",
    "            feat[f'glcm_{prop}'] = float(val)\n",
    "\n",
    "        # --- FFT energy ---\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        mag = np.abs(fshift)\n",
    "        feat['fft_energy'] = float(np.log1p(mag).sum())\n",
    "\n",
    "        # --- ORB keypoints count ---\n",
    "        orb = cv2.ORB_create()\n",
    "        kp = orb.detect(gray, None)\n",
    "        feat['orb_keypoints'] = len(kp)\n",
    "\n",
    "        # --- Simple Blob Detection ---\n",
    "        detector = cv2.SimpleBlobDetector_create()\n",
    "        blobs = detector.detect(gray)\n",
    "        feat['blob_count'] = len(blobs)\n",
    "\n",
    "        return feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main loop\n",
    "for rel, lbl in categories.items():\n",
    "    folder = os.path.join(base_path, rel)\n",
    "    for fn in os.listdir(folder):\n",
    "        if fn.lower().endswith(('.jpg','.png','.jpeg')):\n",
    "            fdata = extract_features(os.path.join(folder, fn), lbl)\n",
    "            if fdata: features.append(fdata)\n",
    "\n",
    "# Save all\n",
    "df = pd.DataFrame(features)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved {len(features)} feature rows to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2507c944-7928-44f6-9544-5eb83165dda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features from 100 test images → saved to test_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
    "\n",
    "# Paths\n",
    "test_path = 'data/test'\n",
    "output_csv = 'test_features.csv'\n",
    "\n",
    "# Parameters\n",
    "LBP_RADIUS = 1\n",
    "LBP_N_POINTS = 8 * LBP_RADIUS\n",
    "LBP_METHOD = 'uniform'\n",
    "LBP_N_BINS = LBP_N_POINTS + 2\n",
    "HOG_PIXELS_PER_CELL = (8, 8)\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "HOG_ORIENTATIONS = 9\n",
    "GLCM_DISTANCES = [1, 2, 4]\n",
    "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "GLCM_PROPS = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "features = []\n",
    "\n",
    "def extract_features(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        w, h = img.size\n",
    "        img_cv = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img_cv, (128, 128))\n",
    "        area = w * h\n",
    "\n",
    "        arr128 = np.array(img.resize((128,128)))\n",
    "        gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "        hsv = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        feat = {\n",
    "            'file': os.path.basename(img_path),\n",
    "            'width': w,\n",
    "            'height': h,\n",
    "            'aspect_ratio': round(w/h, 3),\n",
    "            'file_size_kb': round(os.path.getsize(img_path)/1024.0, 2),\n",
    "        }\n",
    "\n",
    "        for ch,name in enumerate(('r','g','b')):\n",
    "            vals = arr128[:,:,ch].ravel().astype(np.float32)\n",
    "            feat[f'avg_{name}']  = vals.mean()\n",
    "            feat[f'var_{name}']  = vals.var()\n",
    "            feat[f'skew_{name}'] = ((vals - vals.mean())**3).mean() / (vals.std()**3 + 1e-6)\n",
    "\n",
    "        for i,ch in enumerate(('h','s','v')):\n",
    "            hist = cv2.calcHist([hsv],[i],None,[256],[0,256]).flatten()[:20]\n",
    "            for j,v in enumerate(hist):\n",
    "                feat[f'{ch}_hist_{j}'] = int(v)\n",
    "\n",
    "        ghist = cv2.calcHist([gray],[0],None,[256],[0,256]).flatten()[:20]\n",
    "        for i,v in enumerate(ghist): feat[f'gray_hist_{i}'] = int(v)\n",
    "\n",
    "        lum = (0.299*arr128[:,:,0] + 0.587*arr128[:,:,1] + 0.114*arr128[:,:,2]).astype(np.uint8)\n",
    "        lhist = cv2.calcHist([lum],[0],None,[256],[0,256]).flatten()[:20]\n",
    "        for i,v in enumerate(lhist): feat[f'lum_hist_{i}'] = int(v)\n",
    "\n",
    "        feat['contrast'] = int(gray.max() - gray.min())\n",
    "        lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        feat['laplacian_var'] = float(lap.var())\n",
    "\n",
    "        can = cv2.Canny(gray,100,200); can_cnt = int((can>0).sum())\n",
    "        sobx= cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=3)\n",
    "        soby= cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=3)\n",
    "        sobm= np.sqrt(sobx**2 + soby**2).astype(np.uint8)\n",
    "        sob_cnt = int((sobm>50).sum())\n",
    "\n",
    "        feat['canny_count'] = can_cnt\n",
    "        feat['sobel_count'] = sob_cnt\n",
    "        feat['edge_density'] = can_cnt / (area + 1e-6)\n",
    "\n",
    "        cx,cy,half = 64,64,32\n",
    "        mask = np.zeros_like(gray, bool)\n",
    "        mask[cy-half:cy+half,cx-half:cx+half]=True\n",
    "        feat['center_edge'] = int((can[mask]>0).sum())\n",
    "        feat['surround_edge'] = int((can[~mask]>0).sum())\n",
    "\n",
    "        hf = hog(gray,\n",
    "                 orientations=HOG_ORIENTATIONS,\n",
    "                 pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "                 cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "                 block_norm='L2-Hys',\n",
    "                 feature_vector=True)[:50]\n",
    "        for i,v in enumerate(hf): feat[f'hog_{i}'] = float(v)\n",
    "\n",
    "        lbp = local_binary_pattern(gray, LBP_N_POINTS, LBP_RADIUS, method=LBP_METHOD)\n",
    "        lh, _ = np.histogram(lbp.ravel(), bins=LBP_N_BINS, range=(0,LBP_N_BINS))\n",
    "        lh = lh.astype(float)/ (lh.sum()+1e-6)\n",
    "        for i,v in enumerate(lh[:20]): feat[f'lbp_{i}'] = float(v)\n",
    "\n",
    "        glcm = graycomatrix(gray, distances=GLCM_DISTANCES, angles=GLCM_ANGLES,\n",
    "                            symmetric=True, normed=True)\n",
    "        for prop in GLCM_PROPS:\n",
    "            val = graycoprops(glcm, prop).mean()\n",
    "            feat[f'glcm_{prop}'] = float(val)\n",
    "\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        mag = np.abs(fshift)\n",
    "        feat['fft_energy'] = float(np.log1p(mag).sum())\n",
    "\n",
    "        orb = cv2.ORB_create()\n",
    "        kp = orb.detect(gray, None)\n",
    "        feat['orb_keypoints'] = len(kp)\n",
    "\n",
    "        detector = cv2.SimpleBlobDetector_create()\n",
    "        blobs = detector.detect(gray)\n",
    "        feat['blob_count'] = len(blobs)\n",
    "\n",
    "        return feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Loop through test folder\n",
    "features = []\n",
    "for fname in os.listdir(test_path):\n",
    "    if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(test_path, fname)\n",
    "        feat = extract_features(img_path)\n",
    "        if feat: features.append(feat)\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(features)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Extracted features from {len(df)} test images → saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
